# Image Generation Prompts for AI Interview Trainer

This document contains all the image generation prompts (optimized for Veo 3.1 image mode, Midjourney, DALL-E, etc.) to enhance the user experience.

## Image 1: The AI Interview Reality
**Location:** Stats Section (after hero, before stats)
**Purpose:** Show that AI usage is widespread and normal
**Aspect Ratio:** 16:9 (landscape)

### Image Generation Prompt:
```
Wide angle view of modern tech office, diverse software developer at desk with dual monitors, left monitor shows VS Code with GitHub Copilot suggestions autocompleting code in real-time, right monitor displays ChatGPT conversation about debugging, developer looking thoughtful and confident while reviewing AI suggestions, clean minimal workspace, natural window lighting, professional atmosphere, subtle blue and purple accent lighting from screens, photorealistic, high detail, 4K quality
```

**Alternative Prompt (Simpler):**
```
Professional software developer working at modern desk setup, laptop screen clearly showing GitHub Copilot code suggestions, secondary monitor with ChatGPT open, developer reviewing AI output thoughtfully, bright modern office, natural lighting, clean aesthetic, photorealistic
```

**Visual Notes:**
- Should feel professional and normal, not secretive
- Clear view of AI tools on screen
- Developer looking engaged and thoughtful
- Modern, clean tech workspace aesthetic

---

## Image 2: The AI Interview Challenge (Good vs Bad)
**Location:** ForWho Section (after title, before candidate/interviewer cards)
**Purpose:** Contrast bad vs good AI usage in interviews
**Aspect Ratio:** 16:9 (landscape)

### Image Generation Prompt:
```
Split-screen interview scene composition, LEFT SIDE: nervous candidate staring blankly at laptop with ChatGPT code visible, hand hovering over copy-paste, interviewer in background with skeptical crossed arms expression, subtle red color temperature; RIGHT SIDE: confident candidate gesturing while explaining code to engaged interviewer who is leaning forward attentively, laptop showing same ChatGPT code but candidate pointing at specific lines, subtle green color temperature, professional video interview setting, natural lighting, modern home office, photorealistic, cinematic quality
```

**Alternative Prompt (Simpler):**
```
Side-by-side comparison image, left panel shows candidate mindlessly copying code from ChatGPT looking confused, right panel shows candidate confidently explaining AI-generated code to interviewer, professional interview setting, good vs bad contrast, photorealistic
```

**Visual Notes:**
- Perfect vertical split (50/50)
- Identical room setup on both sides for fair comparison
- Facial expressions are key: confused vs confident
- Subtle color grading: cooler/red on left, warmer/green on right
- Both showing the same ChatGPT code to emphasize behavior difference

---

## Image 3: Playground Interface Screenshot
**Location:** PlaygroundFeature Section (after title/description, before feature grid)
**Purpose:** Show the actual playground interface
**Aspect Ratio:** 16:9 (landscape)

### Image Generation Prompt:
```
Professional UI screenshot of modern web application interface, left sidebar with vertical list of coding questions and category filters in blue and purple gradients, main content area shows large card with "Good vs Bad Approaches" title, split layout displaying green-bordered good approach card on left with checkmark icon and red-bordered bad approach card on right with X icon, clean typography, white background with subtle gradient, glassmorphic design elements, professional software interface, sharp and crisp UI elements, 4K quality, modern SaaS application aesthetic
```

**Alternative Prompt (Simpler):**
```
Screenshot of learning platform interface showing sidebar navigation and main content with good vs bad comparison cards, green and red color coding, modern clean UI design, professional web application
```

**Visual Notes:**
- Should look like a real production web app
- Clean, professional interface
- Clear visual hierarchy
- Good vs bad comparison should be obvious
- Color coding: green for good, red for bad

---

## Video 4: Candidate Success Story (Optional)
**Location:** Could add in ForWho section for candidates
**Purpose:** Show emotional journey from confused to confident
**Duration:** 15-20 seconds

### Veo 3.1 Prompt:
```
Young software engineer sitting at desk looking stressed and confused about AI interview usage, transitions to them using the training platform on laptop, practicing scenarios, taking notes, then final shot of them in confident video interview explaining their code clearly while using AI tools appropriately, warm color grading, inspiring and hopeful tone, natural progression from struggle to success
```

**Visual Direction:**
- Act 1: Stress/confusion (looking at ChatGPT unsure how to use it)
- Act 2: Learning (using the playground, taking notes, having "aha" moments)
- Act 3: Success (confident in real interview, interviewer smiling)
- Emotional arc should feel authentic and relatable

---

## Video 5: Interviewer Transformation (Optional)
**Location:** Could add in ForWho section for interviewers
**Purpose:** Show interviewer learning to assess AI usage
**Duration:** 15-20 seconds

### Veo 3.1 Prompt:
```
Technical interviewer looking frustrated as candidate uses AI, not knowing how to evaluate them; transition to interviewer using training platform, reviewing good vs bad examples; final scene shows same interviewer confidently asking probing questions about AI-generated code, candidate explaining thoughtfully, productive collaborative atmosphere, professional setting, journey from confusion to competence
```

**Visual Direction:**
- Act 1: Frustration (interviewer watching candidate use ChatGPT, looking unsure)
- Act 2: Learning (reading the scenarios, nodding, taking notes)
- Act 3: Mastery (asking great follow-up questions, engaged conversation)
- Should feel empowering for interviewers

---

## Image 4: Good vs Bad Code Review Example
**Location:** Playground Section (before topic cards and CTA)
**Purpose:** Show concrete example of what users will learn
**Aspect Ratio:** 16:9 (landscape)

### Image Generation Prompt:
```
Split-screen code review comparison, LEFT PANEL (GOOD): close-up of code editor showing Python authentication function with SQL injection vulnerability, red wavy underline highlighting the vulnerable line "SELECT * FROM users WHERE username='" + username + "'", yellow sticky note annotation pointing to issue with text "SQL Injection Risk!", green checkmark icon in corner, developer's hand with pen pointing at screen; RIGHT PANEL (BAD): same code editor but clean without any annotations, cursor at bottom of code, red X icon in corner, suggesting code was accepted without review, professional IDE interface (VS Code style), dark theme, syntax highlighting, photorealistic screen capture quality
```

**Alternative Prompt (Simpler):**
```
Side-by-side comparison of code review, left shows code with security vulnerability highlighted and annotated with green checkmark, right shows same code unmarked with red X, split-screen layout, code editor interface, clear contrast between careful review vs blind acceptance
```

**Visual Notes:**
- Code should be clearly readable
- Specific SQL injection vulnerability should be obvious
- Left (good): Red underline, annotation, checkmark
- Right (bad): Clean code, no review, X mark
- Use realistic code editor styling (VS Code dark theme)

---

## Video 7: Code Review Example (Advanced Version)
**Location:** Could add in Playground section or as example in ForWho
**Purpose:** Show what good code review of AI code looks like
**Duration:** 25-30 seconds

### Veo 3.1 Prompt:
```
Close-up screen recording of code review scenario, candidate's screen showing AI-generated Python function for authentication, candidate carefully reviewing the code line by line, highlighting SQL injection vulnerability in red, explaining the security issue to interviewer, suggesting parameterized queries as fix, interviewer taking notes and asking follow-up questions about edge cases, professional code editor interface, clear code visibility, emphasis on critical thinking and security awareness
```

**Visual Direction:**
- Start with AI-generated code on screen
- Show candidate reading it carefully (cursor moving, highlighting sections)
- Red highlight around the vulnerable SQL concatenation
- Cut to candidate's face explaining the issue
- Show interviewer's impressed reaction
- Back to screen showing the proposed fix

---

## Video 7: Real Interview Comparison (Optional Extended Version)
**Location:** Could replace Video 2 with longer version
**Purpose:** Full narrative of good vs bad interview
**Duration:** 45-60 seconds

### Veo 3.1 Prompt:
```
Parallel storytelling of two technical interviews, Candidate A mindlessly copies AI code without understanding, struggles to explain when asked, interviewer clearly disappointed; Candidate B uses AI strategically, explains their reasoning, identifies AI code issues, proposes improvements, discusses trade-offs, interviewer engaged and impressed; professional video interview setting, modern home offices, authentic reactions, emphasis on communication and understanding over code output, cinematic quality, natural lighting
```

**Visual Direction:**
- Intercut between two interviews happening simultaneously
- Clear contrast in body language and engagement
- Show specific moments:
  - Both get AI code
  - Candidate A just presents it, can't explain
  - Candidate B walks through it, finds issues
- End with split screen of both outcomes (rejection vs success)

---

## Implementation Notes

### Image Specifications
- **Aspect Ratio:** 16:9 (landscape) to fit the containers
- **Resolution:** Minimum 1920x1080 (4K preferred: 3840x2160)
- **Format:** JPG or PNG for web
- **Optimization:** Compress for web (use tools like TinyPNG)
- **File size:** Target <500KB per image for fast loading

### Placement Priority

**Essential (Must Have):**
1. **Image 4** - Good vs bad code review (shows concrete learning example)
2. **Image 2** - Interview challenge (shows the problem we solve)

**Nice to Have (Medium Priority):**
3. **Image 3** - Playground interface (shows the product)
4. **Image 1** - AI reality (sets context)

**Optional (Low Priority):**
5. Images 5-7 - Add if generating more content

### How to Use These Prompts

**For Veo 3.1 (Image Mode):**
- Copy the full prompt directly
- Use 16:9 aspect ratio setting
- Request photorealistic style
- May need to iterate 2-3 times for best results

**For Midjourney:**
- Add `--ar 16:9 --style raw --v 6` to the prompt
- Use `--quality 2` for higher detail
- Example: `[prompt] --ar 16:9 --style raw --v 6 --quality 2`

**For DALL-E 3:**
- Paste the prompt directly
- Select "landscape" orientation
- Use "vivid" style for photorealism or "natural" for softer look

### Fallback Options

If custom image generation isn't feasible:

1. **Stock photography** from:
   - Unsplash, Pexels (free, high quality)
   - iStock, Shutterstock (paid, more specific)
   - Search terms: "developer coding", "tech interview", "code review"

2. **Illustrations:**
   - Commission custom illustrations
   - Use icon libraries (Heroicons, Lucide) to create composed scenes
   - Consider abstract/geometric representations

3. **Screenshots:**
   - Take actual screenshots of the playground interface (Image 3)
   - Use browser dev tools to create clean UI mockups
   - Consider Figma designs if you want perfect control

### Placeholder Design
Current placeholders include:
- Image icon (mountain/photo)
- Title of what the image will show
- The actual generation prompt (for transparency)
- Hover effects for engagement

Simply replace the placeholder `<div>` with:
```jsx
<img
  src="/images/[filename].jpg"
  alt="[description]"
  className="w-full h-full object-cover"
/>
```
